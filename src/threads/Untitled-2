
# Analysis

## Page allocator (Palloc)

Virtual memory in Pintos is divided into two regions: user virtual memory and kernel virtual memory. User virtual memory ranges from virtual address 0 up to PHYS_BASE, which is defined in threads/vaddr.h and defaults to 0xc0000000 (3 GB). Kernel virtual memory occupies the rest of the virtual address space, from PHYS_BASE up to 4 GB. The kernel virtual memory is mapped one-to-one to physical memory. That is, virtual address PHYS_BASE accesses physical address 0, virtual address PHYS_BASE + 0x1234 accesses physical address 0x1234, and so on.

The physical memory (RAM) is divided into two ``pools" called the kernel pool and user pool, respectively. The user pool is for user virtual memory pages, and the kernel pool for everything else. In Pintos, the size of RAM is saved in init_ram_pages (see threads/loader.h) which is approximately 4 MB\footnote{To be exact, the RAM size defaults to 992 pages, that is 3968 KB.}.

In the main function in threads/init.c, palloc_init(user_page_limit) is called, where MAX(init_ram_pages/2, user_page_limit) pages are given to the user pool and the rest of the RAM pages to the kernel pool. Because Pintos does not use the first 1 MB in physical memory as any of the pool, just init_ram_pages - 256 RAM pages are used by two pools. In the default Pintos setting, init_ram_pages - 256 is 736, and this RAM pages are divied in half; half of system RAM is given to the kernel pool and half to the user pool.

void
palloc_init (size_t user_page_limit)
{
  /* Free memory starts at 1 MB and runs to the end of RAM. */
  uint8_t *free_start = ptov (1024 * 1024);
  uint8_t *free_end = ptov (init_ram_pages * PGSIZE);
  size_t free_pages = (free_end - free_start) / PGSIZE;
  size_t user_pages = free_pages / 2;
  size_t kernel_pages;
  if (user_pages > user_page_limit)
    user_pages = user_page_limit;
  kernel_pages = free_pages - user_pages;

  /* Give half of memory to kernel, half to user. */
  init_pool (&kernel_pool, free_start, kernel_pages, "kernel pool");
  init_pool (&user_pool, free_start + kernel_pages * PGSIZE,
             user_pages, "user pool");
}

Each pool uses a bitmap structure (see struct pool's used_map) to figure out the free or non-free RAM pages in the pool. The Pintos's palloc system puts the pool's used_map at its base. approximately 1 page is allocated from each pool for this internal use. So, by default, each pool manages 367 RAM pages.

static void
init_pool (struct pool *p, void *base, size_t page_cnt, const char *name) 
{
  /* We'll put the pool's used_map at its base.
     Calculate the space needed for the bitmap
     and subtract it from the pool's size. */
  size_t bm_pages = DIV_ROUND_UP (bitmap_buf_size (page_cnt), PGSIZE);
  if (bm_pages > page_cnt)
    PANIC ("Not enough memory in %s for bitmap.", name);
  page_cnt -= bm_pages;

  printf ("%zu pages available in %s.\n", page_cnt, name);

  /* Initialize the pool. */
  lock_init (&p->lock);
  p->used_map = bitmap_create_in_buf (page_cnt, base, bm_pages * PGSIZE);
  p->base = base + bm_pages * PGSIZE;
}

Function palloc_get_multiple obtains a group of contiguous free RAM pages and returns a kernel virtual address which is identifying the start of these physical frames. If PAL_USER flag is set, the physical frames are obtained the user pool, otherwise from the kernel pool. This function investigates a designated pool's used_map: if ith bit of this bitmap is false, a kernel virtual page starting from pool->base + PGSIZE*i is free. That is, a RAM page starting from vtop(pool->base + PGSIZE*i) is a free physical frame. Here, notice that bitmap_scan_and_flip finds the first group of page_cnt consecutive bits in pool->used_map that are all set to false, flips them all to true, and returns the index of the first bit in the group.

void *
palloc_get_multiple (enum palloc_flags flags, size_t page_cnt)
{
  struct pool *pool = flags & PAL_USER ? &user_pool : &kernel_pool;
  void *pages;
  size_t page_idx;

  lock_acquire (&pool->lock);
  page_idx = bitmap_scan_and_flip (pool->used_map, 0, page_cnt, false);
  lock_release (&pool->lock);

  pages = pool->base + PGSIZE * page_idx;

  return pages;
}




## Page directory


In Pintos, virtual addresses are structured as a combination of three fields; \inlinett{pd_no} + \inlinett{pt_no} + \inlinett{pg_ofs}. The \inlinett{pd_no} is the most-significant 10 bits of the virtual address (22:31). This field indexes a page directory \inlinett{pd}, and an indexed page directory entry \inlinett{pde}, \inlinett{pd[pd_no]}, points to a page table \inlinett{pt}. Each \inlinett{pde} consists of a physical address of a page table and flags. After obtaining a page table \inlinett{pt} using \inlinett{pd} and \inlinett{pd_no}, \inlinett{pt_no}, which is the next 10 bits of the virtual address (12:21), indexes this page table \inlinett{pt}, and an indexed page table entry \inlinett{pte}, \inlinett{pt[pt_no]}, points to a physical RAM page. Each \inlinett{pte} consists of a physical address of a RAM page and flags. Next, the MMU finally completes address translation by adding the \inlinett{pg_ofs} to the \inlinett{pte}'s physical address.

The main function in threads/init.c calls \inlinett{paging_init()}, which creates and initializes \inlinett{init_page_dir}, a base page directory, and sets up page table with the kernel virtual mapping. Because \inlinett{pd_no} is 10-bit field and each \inlinett{pde} is 4-byte, total 4 KB space (a single page) is required for a page directory, and each page directory can manage at most 1,024 page tables. Also, each page table needs a 4 KB space (a single page), because \inlinett{pt_no} is 10-bit field and each \inlinett{pte} is 4-byte. Thus, each page table can store mappings to the 1,024 RAM pages.

Initially, \inlinett{init_ram_pages} is set to 1,024 approximately, just one page table is necessary for the kernel virtual mapping, that is, mapping between kernel virtual addresses and physical RAM pages. Therefore, \inlinett{init_page_dir} stores one-to-one mapping from the kernel virtual memory to a whole RAM. Notice, here, that there are just mappings, that is, there is no allocation using palloc except some RAM pages to store a page directory and page table. In addition, there is not a ``user virtual mapping'' yet.

Finally, this \inlinett{init_page_dir} is stored into the CR3 register.

static void
paging_init (void)
{
  uint32_t *pd, *pt;
  size_t page;
  extern char _start, _end_kernel_text;

  pd = init_page_dir = palloc_get_page (PAL_ASSERT | PAL_ZERO);
  pt = NULL;
  for (page = 0; page < init_ram_pages; page++)
    {
      uintptr_t paddr = page * PGSIZE;
      char *vaddr = ptov (paddr);
      size_t pde_idx = pd_no (vaddr);
      size_t pte_idx = pt_no (vaddr);
      bool in_kernel_text = &_start <= vaddr && vaddr < &_end_kernel_text;

      if (pd[pde_idx] == 0)
        {
          pt = palloc_get_page (PAL_ASSERT | PAL_ZERO);
          pd[pde_idx] = pde_create (pt);
        }

      pt[pte_idx] = pte_create_kernel (vaddr, !in_kernel_text);   // PTE_U flag가 없음.
    }

  asm volatile ("movl %0, %%cr3" : : "r" (vtop (init_page_dir)));
}







### Page directory for each process

A page directory for each process is stored in \inlinett{struct thread}'s \inlinett{pagedir} member which is created and initialized when a process is loaded. The function \inlinett{load} in userprog/process.c calls \inlinett{pagedir_create} and it shallow-copies \inlinett{init_page_dir} which is initialized in \inlinett{paging_init()}. Because of the shallow copy, only a single page for the page directory is allocated for each process, and page tables are shared among processes. Therefore, the kernel virtual memory is global. It is always mapped the same way, regardless of what user process or kernel thread is running.

uint32_t *
pagedir_create (void) 
{
  uint32_t *pd = palloc_get_page (0);
  if (pd != NULL)
    memcpy (pd, init_page_dir, PGSIZE);
  return pd;
}

This newly created page directory is stored into CR3 register after \inlinett{pagedir_activate} is called.

Whenever a user process needs a user virtual page, \inlinett{upage}, it allocates a RAM page from the user pool and obtains a kernel virtual address, \inlinett{kpage}, that is associated with the RAM page using \inlinett{palloc_get_page} with \inlinett{PAL_USER} flag. Next, it calls \inlinett{pagedir_set_page(cur->pagedir, upage, kpage, writable)} to add mapping between the user virtual page and the physical frame. During this step, if any page table was allocated to \inlinett{cur->pagedir[pd_no(upage)]}, a new table is allocated and registered into the current process's (private) page directory. Therefore, all of the processes share the kernel virtual mappings, but they do not share user virtual mappings.

bool
pagedir_set_page (uint32_t *pd, void *upage, void *kpage, bool writable)
{
  uint32_t *pte;
  ...
  pte = lookup_page (pd, upage, true);   // 해당 위치 pd[pd_no (upage)]에 table이 없으면 새롭게 할당한다. private.

  if (pte != NULL) 
    {
      ASSERT ((*pte & PTE_P) == 0);
      *pte = pte_create_user (kpage, writable);   // PTE_U flag가 추가됨.
      return true;
    }
  else
    return false;
}

Here, \inlinett{lookup_page(pd, vaddr, create)} returns the address of the page table entry for virtual address \inlinett{vaddr} in page directory \inlinett{pd}. If \inlinett{pd} does not have a page table for \inlinett{vaddr}, behavior depends on \inlinett{create}. If \inlinett{create} is true, then a new page table is created and a pointer into it is returned. Otherwise, a null pointer is returned.

Similar functionality is provided by \inlinett{pagedir_get_page}, which finds a RAM page, not a PTE. This function finds the physical address that corresponds to user virtual address \inlinett{uaddr} in \inlinett{pd}, and returns the kernel virtual address corresponding to that RAM page, or null pointer if \inlinett{uaddr} is unmapped.

void *
pagedir_get_page (uint32_t *pd, const void *uaddr) 
{
  uint32_t *pte;

  ASSERT (is_user_vaddr (uaddr));
  
  pte = lookup_page (pd, uaddr, false);
  if (pte != NULL && (*pte & PTE_P) != 0)
    return pte_get_page (*pte) + pg_ofs (uaddr);
  else
    return NULL;
}

When a process terminates its execution, \inlinett{process_exit} calls \inlinett{pagedir_destroy} which deallocates all physical frames mapped to the process's page directory. During this, page deallocation is not performed for kernel virtual mapping, because it is global.

void
pagedir_destroy (uint32_t *pd) 
{
  uint32_t *pde;

  if (pd == NULL)
    return;

  ASSERT (pd != init_page_dir);
  for (pde = pd; pde < pd + pd_no (PHYS_BASE); pde++)
    if (*pde & PTE_P) 
      {
        uint32_t *pt = pde_get_pt (*pde);
        uint32_t *pte;
        
        for (pte = pt; pte < pt + PGSIZE / sizeof *pte; pte++)
          if (*pte & PTE_P) 
            palloc_free_page (pte_get_page (*pte));
        palloc_free_page (pt);
      }
  palloc_free_page (pd);
}

### Frame allocation failed

When each process allocates pyhsical frame through palloc to load a user virtual page and adds virtual-physical mapping to its page directory, every bit in used_map of user pool can be true, that is, there may be no more RAM pages available for allocation. In this case, palloc returns NULL. If no further allocation is possible from the user pool, another physical frame must be evicted so that the requesting process can use it. However, the current Pintos did not implement frame eiviction.



## Current implementation

???





# Solutions to requirements

Lazy loading (supplemental page table), eviction (frame table), mmap system call, stack growth.

## Overview

1. Supplemental page table

A supplemental page table entry (SPTE)는 user virtual page에 대한 정보를 보충한다 (associated with user virtual page). Process마다 load를 요구하는 user virtual page들은 specific하므로 SPTE 또한 process-specific하다. SPTE는 해당 page가 file로부터 읽어들여 초기화를 해야하는지, 그냥 zeros로 채우는지, swap slots으로부터 읽어들이는지 등의 정보를 알려준다.

나중에 lazy loading을 구현하면, 아직 load되지 않은 user virtual page를 access하는 것은 page fault를 일으킨다. 이때, page fault handler에서 해당 page를 어떻게 load해야하는지에 대한 정보가 SPTE에 들어있다.

A supplemental page table (SPT)는 SPTE들을 보관하고 있는 structure이다. 각각의 SPTE는 process-specific하므로, SPT는 각각의 process마다 private하게 보관한다. 주어진 user virtual page에 대해 해당하는 SPTE를 빠르게 lookup하기 위해 hash table을 이용할 것이다.

2. Frame table

A frame table entry (FTE)는 a physical frame from user pool을 identifying하는 kernel virtual address를 hold한다. 즉, user virtual page를 load하기 위해 a physical frame을 할당할 경우 (palloced with PAL_USER), 해당하는 kernel virtual address를 hold하는 FTE가 만들어진다.

A frame table (FT)는 FTE들을 보관하고 있는 structure이다. RAM pages는 어느 process든지 할당할 수 있기 때문에, FT는 global하게 manage된다.

3. Swap slots

더 이상 RAM page를 할당할 수 없을 때, 이미 할당된 page를 evict할 필요가 있다. 이때, 이 page가 dirty하지 않을 경우는 상관이 없는데, dirty할 경우 contents를 backup해두어야 한다. 이때 사용되는 게 swap slots임. Swap slots은 disk에 존재하고 global하게 manage된다.




어떤 process P가 a user virtual page (upage)를 필요로할 때, P는 해당 page에 mapped될 physical frame을 바로 할당하지 않고, SPTE를 만들어서 SPT에 저장한다. 나중에, 이 process가 해당 page 영역을 access하면, not present page fault가 발생한다. 이때, page fault handler는 fault를 발생시킨 process (P)의 SPT에서 upage에 해당하는 SPTE를 찾는다. 그리고 upage를 위한 pyhsical frame을 할당하고 (using frame table manager, 이때 frame과 associated된 FTE가 만들어진다.), SPTE에 저장된 정보를 바탕으로, file이나 swap slot으로부터 contents를 읽어들이거나 zeros로 fill하여 frame을 초기화한다. 마지막으로, upage와 할당된 frame 사이에 mapping을 p->pagedir에 추가한다 (using pagedir_set_page).

Frame table manager can fail to allocate a frame for the user virtual page. 이때, eviction이 요구된다. The manager는 frame table에서 victim FTE을 찾고, 만약 frame이 dirty할 경우 swap slots에 backup하고나서 이 frame을 P에 넘겨준다.


그림.



## Data structures and operations

Supplemental page table entry (SPTE), supplemental page table (SPT), frame table entry (FTE), frame table (FT).

### Supplemental page table management

A supplemental page table entry (SPTE)는 user virtual page에 대한 정보를 보충한다 (associated with user virtual page). Process마다 load를 요구하는 user virtual page들은 specific하므로 SPTE 또한 process-specific하다. SPTE는 해당 page가 file로부터 읽어들여 초기화를 해야하는지, 그냥 zeros로 채우는지, swap slots으로부터 읽어들이는지 등의 정보를 알려준다. 만약, 이 user virtual page가 file로부터 load되어야 한다면, 해당 file에 대한 pointer, starting offset, read amounts에 대한 정보가 추가적으로 필요하다. In the case of loading from a swap slot, which swap slot에 대한 정보, 즉 index가 필요하다. 또한, SPTE->upage를 loading하면서 a physical frame이 할당될 경우, 이 SPTE에는 할당된 frame과 associated된 FTE에 대한 pointer가 저장된다.

/* How to load a user virtual pages? */
enum page_type
  {
    PG_FILE = 1,            /* Load from file. */
    PG_SWAP = 2,            /* Load from swap slot. */
    PG_ZERO = 3,            /* Zero page contents. */
    PG_UNKNOWN = 4          /* Unknown (for debugging purposes). */
  };

/* Supplemental page table entry (SPTE). */
struct page
  {
    void *upage;            /* User virtual page. */
    struct frame *frame;    /* A FTE which is allocated for this SPTE. */

    struct thread *owner;   /* An owner thread. */

    enum page_type type;    /* How to load this page? */
    bool writable;          /* Is page writable? */

    /* Meaningful if type is PG_FILE. */
    struct file *file;      /* A file this page will be loaded from. */
    off_t file_ofs;         /* Offset. */
    size_t read_bytes;      /* File read amount. */
    size_t zero_bytes;      /* PGSIZE - read_bytes. */

    /* Meaningful if type is PG_SWAP. */
    size_t slot;            /* A swap slot index this page will be loaded from. */

    struct hash_elem hash_elem;
  };

SPT의 life cycle은 아래 두 함수를 통해 관리된다.

struct hash *page_create_spt (void);
void page_destroy_spt (struct hash *spt);





page_create_spt는 SPTE를 보관하기 위한 SPT를 만들고 초기화한다 (managed as hash table). 이 hash table은 SPTE의 upage를 key로 entries를 저장한다 (see page_hash_func and page_hash_less).

struct hash *
page_create_spt (void)
{
  struct hash *spt = malloc (sizeof (struct hash));
  if (!spt)
    PANIC ("cannot create supplemental page table.");
  hash_init (spt, page_hash_func, page_hash_less, NULL);
  return spt;
}

Process가 program을 load할 때 SPT를 만든다.

bool
load (const char *exec_path, void (**eip) (void), void **esp) 
{
  ...

  t->spt = page_create_spt ();
  if (t->spt == NULL)
    goto done;

  ...
}

이렇게 만들어진 SPT는 process가 exit할 때 resource를 deallocate해야 한다.

void
process_exit (void)
{
  struct thread *cur = thread_current ();
  struct hash *spt;

  ...
  
  spt = cur->spt;
  if (spt != NULL)
    page_destroy_spt (spt);
  
  ...
}

page_destroy_spt는 주어진 SPT에 저장된 모든 SPTE에 대해 할당을 해제한다. ***** SPTE를 할당 해제할 때는 synchronization을 고려해야한다. *****

void
page_destroy_spt (struct hash *spt)
{
  ASSERT (spt != NULL);
  hash_destroy (spt, page_hash_free);
  free (spt);
}

static void
page_hash_free (struct hash_elem *e, void *aux UNUSED)
{
  struct page *p = hash_entry (e, struct page, hash_elem);
  struct frame *f = p->frame;
  ...// Synchronization
  free (p);
}




각 process는 page_make_entry 함수를 이용하여 SPTE를 생성하고 이 process의 SPT에 저장한다. 이 함수는 생성된 SPTE를 가리키는 pointer를 리턴하는데, 이를 이용하여 type을 설정하고 필요한 정보들(e.g., file, offset, read_bytes)을 설정해야한다.

struct page *
page_make_entry (void *upage)
{
  struct thread *cur = thread_current ();
  struct page *p;

  if (page_lookup (upage))
    return NULL;
  if ((p = malloc (sizeof (struct page))) == NULL)
    PANIC ("cannot create supplemental page table entry.");
  
  p->upage = upage;
  p->frame = NULL;
  p->owner = cur;

  p->type = PG_UNKNOWN;
  p->file = NULL;
  p->slot = BITMAP_ERROR;

  hash_insert (cur->spt, &p->hash_elem);
  return p;
}

Here, finding a SPTE associated with given upage is performed by page_lookup. This function returns a pointer to the corresponding SPTE if exists, or NULL otherwise. Therefore, in the function page_make_entry, a request to create an already existing SPTE is denied.

struct page *
page_lookup (void *upage)
{
  struct thread *cur = thread_current ();
  struct page key;
  struct hash_elem *e;

  key.upage = upage;
  e = hash_find (cur->spt, &key.hash_elem);

  return e != NULL ? hash_entry (e, struct page, hash_elem) : NULL;
}

Function page_remove_entry removes a given SPTE. If FTE is allocated for this SPTE, it is also removed. Importantly, a physical frame associated with this FTE is ``not'' deallocated. This frame will be deallocated by pagedir_destroy when a process exits. There are so many critical cases we have to consider. So page_remove_entry will be covered later.

User virtual page upage에 대해 page를 loading할 때는 page_load 함수를 이용한다. ***** lazy loading에서 설명 *****

bool page_load (void *upage);





### Frame table management

User process에서 만든 SPTEs를 이용하여 user virtual pages를 loading할 때, pyhsical frame을 할당해주어야 한다. 원래는 palloc_get_page (PAL_USER)를 이용하여 physical frame을 user pool에서 할당한 후 이를 identifying하는 kernel virtual address를 리턴하는데, 이제는 we will use operations on FTEs (not directly using palloc).

A frame table entry (FTE)는 a physical frame allocated from user pool을 identifying하는 kernel virtual address를 hold한다. 만약, SPTE->upage를 위해 a physical frame F가 allocated되었다면, F와 associated된 FTE에는 이 SPTE가 기록된다.

/* Frame table entry (FTE). */
struct frame
  {
    void *kpage;            /* Kernel virtual page identifying a physical frame. */
    struct page *suppl;     /* A SPTE which requested this FTE. */

    struct thread *owner;   /* An owner thread (for debugging purposes). */

    struct list_elem list_elem;
  };

A frame table (FT)는 FTE들을 보관하고 있는 structure이다. 이 table은 global하고 모든 processes들이 접근할 수 있기때문에, searching, inserting, removing an FTE는 synchronized되어야한다.

static struct lock table_lock;   /* Mutual exclusion. */
static struct list frame_list;   /* Mapped frames (list). */

FT는 kernel이 실행될 때 threads/init.c의 main function에서 한 번 초기화된다.

void
frame_init (void)
{
  lock_init (&table_lock);
  list_init (&frame_list);
}

int
main (void)
{
  ...
  frame_init ();
  ...
}



Phsical frame을 할당하여 이를 identifying하는 kernel virtual page를 리턴하거나 할당을 해제하는 것은 palloc을 통해 직접 이루어지지 않고, FTE에 wrapped되어 frame_alloc과 frame_free함수를 통해 간접적으로 이루어진다.

struct frame *frame_alloc (struct page *p);
void frame_free (struct frame *f);

frame_alloc(p)는 SPTE p를 위해 RAM page를 할당하는 기능을 수행한다. A physical frame이 SPTE p를 위해 할당될 때, FTE가 하나 만들어지고 이 frame을 identifying하는 kernel virtual address가 FTE에 저장된다. 또한, 할당을 요청한 SPTE p를 가리키는 pointer도 setup된다. 이렇게 만들어진 FTE는 FT에 저장이 되는데, 이 전 과정은 lock을 이용하여 atomic하게 이루져야한다.

struct frame *
frame_alloc (struct page *p)
{
  struct thread *cur = thread_current ();
  struct frame *f;

  lock_acquire (&table_lock);

  if ((f = malloc (sizeof (struct frame))) == NULL)
    PANIC ("cannot allocate frame table entry.");

  f->kpage = palloc_get_page (PAL_USER));
  if (f->kpage != NULL)
    {
      f->owner = p->owner;
      f->suppl = p;

      list_push_back (&frame_list, &f->list_elem);
      lock_release (&table_lock);

      return f;
    }
  else
    PANIC ("eviction required. covered later.");
}




Function frame_free removes a given FTE. Importantly, a physical frame associated with this FTE is ``not'' deallocated. This frame will be deallocated by pagedir_destroy when a process exits. There are so many critical cases we have to consider. So frame_free will be covered later.



더 이상 할당 가능한 physical frame이 없을 때에는 victim frame을 찾아야 하는데, 이는 frame_get_victim 함수를 통해 이루어진다. ***** eviction에서 설명 *****

struct frame *frame_get_victim (void);





### Swap slots management

더 이상 RAM page를 할당할 수 없을 때, 이미 할당된 physical frame을 evict할 필요가 있다. 이때, 이 page가 dirty하지 않을 경우는 상관이 없는데, dirty할 경우 contents를 backup해두어야 한다. 이때 사용되는 게 swap slots이다. Swap slots은 global한 disk 영역에 존재하기 때문에, frame table과 마찬가지로 accessing swap slots은 synchronized되어야한다.

static struct lock swap_lock;

각 swap slot은 page size만큼의 연속된 disk sectors를 populate한다. Size of a disk sector는 BLOCK_SECTOR_SIZE에 define되어 있다. 따라서, page-size swap slot을 위해 필요한 sector의 개수는 PGSIZE / BLOCK_SECTOR_SIZE가 된다.

#define PAGE_SECTOR_CNT (PGSIZE / BLOCK_SECTOR_SIZE)

여러 swap slots들 중에서 사용 중인 slots과 free slots을 구분해야 하는데, 이를 위해서 palloc.c의 implementation과 같이 bitmap used_map을 이용한다. used_map의 ith bit가 true이면 ith slot이 사용 중이고, 그렇지 않으면 free slot이다.

static struct bitmap *used_map;



Swap slots manger는 kernel이 실행될 때 threads/init.c의 main function에서 한 번 초기화된다. Document에서 제시한 대로, we will use the BLOCK_SWAP block device for swapping, obtaining the struct block that represents it by calling block_get_role().

static struct block *swap_bdev;
static size_t swap_slots;

void
swap_init (void)
{
  if (!(swap_bdev = block_get_role (BLOCK_SWAP)))
    PANIC ("possible?");

  swap_slots = block_size (swap_bdev) / PAGE_SECTOR_CNT;
  used_map = bitmap_create (swap_slots);

  if (!used_map)
    PANIC ("bitmap allocation failed.");
  
  lock_init (&swap_lock);
}

int
main (void)
{
  ...
  swap_init ();
  ...
}

Physical frame의 contents를 swap slot에 write하고 read하는 작업은 swap_out과 swap_in을 통해 각각 이루어진다.

size_t swap_out (void *kpage);
void swap_in (void *kpage, size_t slot);

swap_out 함수는 swap_bdev에서 free slot을 찾아서 해당하는 slot에 pyhsical frame의 contents를 write한다.

size_t
swap_out (void* kpage)
{
  size_t size = PGSIZE;
  size_t slot;
  block_sector_t sector;
  int i;

  lock_acquire (&swap_lock);
  slot = bitmap_scan_and_flip (used_map, 0, 1, false);
  lock_release (&swap_lock);

  if (slot != BITMAP_ERROR)
    {
      sector = slot * PAGE_SECTOR_CNT;
      for (i = 0; i < PAGE_SECTOR_CNT; i++)
        {
          block_write (swap_bdev, sector + i,
                       kpage + BLOCK_SECTOR_SIZE * i);
        }
      return slot;
    }
  else
    PANIC ("cannot find any free swap slot.");
}

이렇게 backup된 contents는 나중에 swap_in 함수를 이용하여 user virtual page에 mapped된 pyhsical frame에 restore될 수 있다.

void
swap_in (void *kpage, size_t slot)
{
  block_sector_t sector;
  int i;

  sector = slot * PAGE_SECTOR_CNT;
  for (i = 0; i < PAGE_SECTOR_CNT; i++)
    {
      block_read (swap_bdev, sector + i,
                  kpage + BLOCK_SECTOR_SIZE * i);
    }

  bitmap_set_multiple (used_map, slot, 1, false);
}

## Integration of data structures and operations

### Lazy loading

Currently, executable code and data segments are directly loaded in memory during process setup. However, we have to modify some portion of the current implementation so that only a stack setup part is directly loaded when a process starts. That is, when a process is loading a program, every necessary page (except stack) is not loaded during the time. 따라서, 나중에 procee가 unloaded segments에 접근하면 not-present page fault가 발생하는데, 이때 page fault handler가 해당 user virtual pages을 load하고 process의 execution을 resume하도록 해야한다.

Page fault handler가 해당 user virtual page를 어떻게 load해야 하는지 알기 위해서는 process가 SPTE들을 만들어서 필요한 정보들을 저장해 두어야 한다. Therefore, we will modify load_segment in userprog/process.c so that it just makes SPTE which contains supplemental information without allocating any physical frame.

static bool
load_segment (struct file *file, off_t ofs, uint8_t *upage,
              uint32_t read_bytes, uint32_t zero_bytes, bool writable) 
{
  ...
  while (read_bytes > 0 || zero_bytes > 0) 
    {
      size_t page_read_bytes = read_bytes < PGSIZE ? read_bytes : PGSIZE;
      size_t page_zero_bytes = PGSIZE - page_read_bytes;
      struct page *p;

      if ((p = page_make_entry (upage)) == NULL)
        return false;
      if (page_read_bytes > 0)
        {
          p->type = PG_FILE;
          p->file = file;
          p->file_ofs = ofs;
        }
      else
        p->type = PG_ZERO;
      
      p->writable = writable;
      p->read_bytes = page_read_bytes;
      p->zero_bytes = page_zero_bytes;

      read_bytes -= page_read_bytes;
      zero_bytes -= page_zero_bytes;
      upage += PGSIZE;
      ofs += page_read_bytes;
    }
  return true;
}

Process가 these not present pages에 access할 때, page fault가 발생하고 fault address가 contain된 user virtual page를 얻어 page_load 함수를 호출한다.

static void
page_fault (struct intr_frame *f) 
{
  ...
  asm ("movl %%cr2, %0" : "=r" (fault_addr));
  fault_page = pg_round_down (fault_addr);

  ...
  if (not_present)
    {
      if (!page_load (fault_page))
        sys_exit (-1);
      return;
    }

  if (!user)
    {
      f->eip = (void (*) (void)) f->eax;
      f->eax = (uint32_t) SYS_BAD_ADDR;
      return;
    }

  kill (f);
}


page_load looks up the SPTE that is associated with virtual page that faulted in the process's SPT. 그리고 SPTE p에 FTE와 physical frame을 할당한다 using frame_alloc (p). 이후, p->type에 따라 file이나 swap slot에서 contents를 read하거나 zeros로 fill한다. 마지막으로 install_page 함수를 이용하여 이 process에 user virtual mapping을 추가한다.

bool
page_load (void *upage)
{
  struct page *p = page_lookup (upage);
  if (!p)
    return false;

  struct frame *f = p->frame = frame_alloc (PAL_USER, p);
  if (p->file != NULL)
    {
      size_t read_bytes
        = file_read_at (p->file, f->kpage, p->read_bytes, p->file_ofs);
      if (read_bytes != p->read_bytes)
        {
          frame_free (f);
          return false; 
        }
      memset (f->kpage + p->read_bytes, 0, p->zero_bytes);
    }
  else if (p->slot != BITMAP_ERROR)
    PANIC ("p should have been once evicted. covered later.");
  else
    memset (f->kpage, 0, PGSIZE);

  if (!install_page (upage, f->kpage, p->writable)) 
    {
      frame_free (f);
      return false; 
    }

  frame_unlock (f);
  return true;
}

The function install_page(upage, kpage, writable) adds a mapping from user virtual page to kernel virtual page that is identifying a physical frame to the calling process's pagedir. If writable is true, the user process may modify the page, otherwise, it is read-only. In this function upage must not already be mapped. It returns true on success, false if upage is already mapped or if memory allocation fails.

static bool
install_page (void *upage, void *kpage, bool writable)
{
  struct thread *t = thread_current ();
  return (pagedir_get_page (t->pagedir, upage) == NULL
          && pagedir_set_page (t->pagedir, upage, kpage, writable));
}

Notice that the initial stack segment (actually a single page when process starts) is ``not'' lazily loaded. That is, it is loaded immediately during process start up. However, if stack growth is needed, all the necessary stack virtual pages are lazily loaded.

static bool
setup_stack (void **esp) 
{
  bool success = false;
  void *upage = ((uint8_t *) PHYS_BASE) - PGSIZE;
  struct page *p = page_make_entry (upage); 
  if (!p)
    return false;
  else
    {
      p->type = PG_ZERO;
      p->writable = true;

      success = page_load (upage);
      if (success)
        *esp = PHYS_BASE;
    }
  return success;
}



### Stack growth

The current implementation imposes a fixed size on the stack (single page). That is, a stack cannot grow down below the limited size. The requirement is to make it available to increase a size of the stack. We will impose a maximum limit on stack growth (STACK_MAX, 8MB). Lazy loading과 비슷하게, ESP register가 fixed-size stack 밑을 access할 경우 page fault가 발생한다. 이때, the handler first check whether a it needs a stack growth or not. If stack growth is needed, the handler retrieves a required stack page address. After this, it makes a SPTE associated with this stack page, and then 바로 page_load를 호출한다.

To check whether the stack growth is necessary, we use this condition.

static bool
stack_growth (void *vaddr, void *esp)
{
  return vaddr > (PHYS_BASE - STACK_MAX)
         && vaddr <= (PHYS_BASE - 1);
         && vaddr >= (esp - 32);
}

Using this function, page fault handler checks the necessity of stack growth, makes SPTE, and then loads it.

static void
page_fault (struct intr_frame *f) 
{
  ...
  asm ("movl %%cr2, %0" : "=r" (fault_addr));
  fault_page = pg_round_down (fault_addr);

  esp = user ? f->esp : cur->saved_esp;
  if (stack_growth (fault_addr))
    {
      if ((p = page_make_entry (fault_page)))
        {
          p->type = PG_ZERO;
          p->writable = true;
        }
    }

  if (not_present)
    {
      if (!page_load (fault_page))
        sys_exit (-1);
      return;
    }

  ...
  kill (f);
}

Here, we need to obtain the current value of the user program's stack pointer. If a page fault occurs in the user program, we can retrieve it from the esp member of the intr_frame f. On the other hand, we cannot retrieve it from f if a page fault occured in the kernel, because the processor only saves the stack pointer when an exception causes a ``switch" from user to kernel mode. Thus, in this case, reading esp out of the struct intr_frame passed to page_fault() would yield an undefined value. So we've saved esp into struct thread on the initial transition from user to kernel mode.

static void
syscall_handler (struct intr_frame *f) 
{
  struct thread *cur = thread_current ();
  cur->saved_esp = esp;
  ...
}





### Evicting a frame

To evict a FTE and its associated physical frame, two functions communicate each other; frame_alloc and page_load. In function frame_alloc, eviction이 필요한 조건은 palloc_get_page(PAL_USER)가 fail할 경우이다.

struct frame *
frame_alloc (struct page *p)
{
  struct thread *cur = thread_current ();
  struct frame *f;
  bool dirty;

  lock_acquire (&table_lock);

  if ((f = malloc (sizeof (struct frame))) == NULL)
    PANIC ("cannot allocate frame table entry.");

  f->kpage = palloc_get_page (PAL_USER);
  if (f->kpage != NULL)
    ...
  else
    {
      /* Gets a FTE associated with victim physical frame. */
      free (f);
      f = frame_get_victim ();
      
      /* Performs eviction.
         Gives an existing frame f to the new SPTE p. */
      frame_do_eviction (f, p);
      
      lock_release (&table_lock);
      return f;
    }
}

A process가 frame_alloc(p)를 호출했을 때, eviction이 필요하다면, frame_get_victim 함수를 이용하여 적절한 victim FTE f를 선정하고 frame_do_eviction(f, p)를 호출한다. 여기서, f->suppl은 이전에 이 FTE을 request하여 reply받았던 SPTE이고, f->suppl->owner는 이 SPTE의 owner process이다. Eviction을 수행하기 위해, 먼저 f에 associated된 physical frame이 dirty한지 확인한다. dirty 여부는 이 frame이 mapped된 user virtual page와 pagedir_is_dirty 함수를 이용하여 확인한다. 만약 dirty할 경우, swap slot에 backup할 필요가 있다 using swap_out. 다음으로, f->suppl->owner의 pagedir에서 user virtual mapping between f->suppl->upage and a physical frame identified by f->kpage를 지운다 using pagedir_clear_page. 따라서, f->suppl->owner process가 나중에 f->suppl->upage를 access할 경우, not-present page fault가 발생하여 lazy load step을 다시 밟게 된다 (해당하는 SPTE, 즉 f->suppl은 삭제되지 않았기 때문에.)

swap_out 함수는 page contents를 a free swap slot에 backup하고 해당 slot의 index를 리턴한다. 나중에, f->suppl->upage에 대한 access는 page fault를 발생시키고, 이는 page_load를 이용한 re-load procedure로 이어지는데, 이때는 file로부터 읽어들이거나 zeros로 fill하지 않고 contents가 backup되어 있는 swap slot으로부터 page를 load해야한다. 따라서, f->suppl->slot에 contents가 backup된 swap slot의 index를 save하고 f->suppl->type을 PG_SWAP으로 변경한다. 또한, SPTE f->suppl이 처음에 from-file-load로 setup되어있을 수 있기 때문에 f->suppl->file을 NULL로 바꿔주고, 이 SPTE는 더 이상 할당된 frame이 없기 때문에 f->suppl->frame도 NULL로 바꿔준다.

마지막으로, victim FTE f에 대해 f->suppl과 f->owner를 각각 새로운 SPTE인 p와 p->owner로 바꿔준 후, frame table에 ``push back''하고 해당 FTE를 리턴한다

static void
frame_do_eviction (struct frame *v, struct page *p)
{
  ASSERT (lock_held_by_current_thread (&table_lock));

  /* Removes a victim FTE from FT. */
  list_remove (&v->list_elem);

  /* Checks whether the victim RAM page is dirty and then
     removes virtual mapping. */
  bool dirty = pagedir_is_dirty (v->suppl->owner->pagedir, v->suppl->upage);
  pagedir_clear_page (v->suppl->owner->pagedir, v->suppl->upage);

  /* The victim frame has been modified. */
  if (dirty)
    {
      /* Saves the previous contents to the swap slot and
         Re-initializes supplemental information for later
         page fault handling. */
      v->suppl->slot = swap_out (v->kpage);
      v->suppl->type = PG_SWAP;
      v->suppl->file = NULL;
      v->suppl->frame = NULL;
    }

  /* Changes owner. */
  v->owner = p->owner;
  v->suppl = p;

  list_push_back (&frame_list, &v->list_elem);
}




Once a user virtual page identified by an SPTE p is swapped out, p->type is PG_SWAP, p->file is NULL, and p->slot is ``not'' BITMAP_ERROR. Afterwards, when a page is loaded by page_load, it loads this page from a swap slot identified by p->slot. After that, we must reset p->slot to BITMAP_ERROR because the user virtual page is not in the swap slot anymore.

bool
page_load (void *upage)
{
  struct page *p = page_lookup (upage);
  if (!p)
    return false;

  struct frame *f = p->frame = frame_alloc (PAL_USER, p);
  if (p->file != NULL)
    ...
  else if (p->slot != BITMAP_ERROR)
    {
      swap_in (f->kpage, p->slot);
      p->slot = BITMAP_ERROR;
    }
  else
    ...

  if (!install_page (upage, f->kpage, p->writable)) 
    {
      frame_free (f);
      return false; 
    }

  frame_unlock (f);
  return true;
}





### File memory mapping

Two system calls should be implemented; mmap and munmap. Therfore SYSCALL_CNT is increased from 13 to 15, and two system call wrappers and two core system call functionalities will be added.

#define SYSCALL_CNT 15

static void sys_mmap_wrapper   (struct intr_frame *);
static void sys_munmap_wrapper (struct intr_frame *);

mapid_t sys_mmap (int, void *);
void    sys_munmap (mapid_t);

In each process context, there can be several mmap mappings. Therefore, each process needs to keep these mappings. In addition, each mapping should contain its id and information about which file is mapped and which virtual page this mapping starts from.

/* A mmap mapping. */
struct mmap
  {
    struct list_elem mmap_list_elem;   /* List element. */
    struct file *file;                 /* File. */
    mapid_t mapid;                     /* Mmap id. */
    
    /* A user virtual page from which mapping starts. */
    void *addr;
    size_t pages;
  };

struct thread
  {
    ...

    /* Shared between thread.c and syscall.c. */
    struct list mmap_list;   /* List of mmap mappings. */
    int next_mapid;          /* Next file descriptor number. */

    ...
  };

Here, mmap_list and next_mapid are initialized by init_thread(), and the initial value of next_mapid is 0.

System call mmap(fd, addr) maps the file open as fd into the process's virtual address space. The entire file is mapped into consecutive virtual pages starting at addr. If the file's length is not a multiple of PGSIZE, then some bytes in the final mapped page "stick out" beyond the end of the file. *****Set these bytes to zero when the page is faulted in from the file system, and discard them when the page is written back to disk.***** This function returns, if successful, a mapping id thaa uniquely indentifies the mapping within the process. On failure, it returns -1 and the process's mappings are unchanged.

A call to mmap may fail if the file open as fd has a length of zero bytes. It must fail if addr is not ``page-aligned'' or if the range of pages mapped overlaps any existing set of mapped pages, including the stack or pages mapped at executable load time. It must also fail if addr is 0, because some Pintos code assumes virtual page 0 is not mapped. Finally, file descriptors 0 and 1, representing console input and output, are not mappable.

Closing or removing a file does not unmap any of its mappings. Once created, a mapping is valid until munmap is called or the process exits, following the Unix convention. We should use the file_reopen function to obtain a separate and independent reference to the file for each of its mappings.

/*Your VM system must lazily load pages in mmap regions and use the mmaped file itself as backing store for the mapping. That is, evicting a page mapped by mmap writes it back to the file it was mapped from.*/

mapid_t
sys_mmap (int fd_no, void *addr)
{
  struct thread *cur = thread_current ();
  struct file_desc *fd;
  struct file *f;
  struct mmap *m;
  size_t size;
  off_t ofs = 0;

  if (fd_no == STDIN_FILENO || fd_no == STDOUT_FILENO)
    return -1;
  if (addr == NULL || pg_ofs (addr) != 0)
    return -1;
  if ((fd = find_file_desc (fd_no)) == NULL)
    return -1;
  if ((m = malloc (sizeof (struct mmap))) == NULL)
    return -1;
  
  lock_acquire (&fs_lock);
  if ((f = file_reopen (fd->file)) == NULL)
    {
      lock_release (&fs_lock);
      free (m);
      return -1;
    }
  lock_release (&fs_lock);

  m->file = f;
  m->mapid = cur->next_mapid++;
  m->addr = addr;
  m->pages = 0;
  list_push_back (&cur->mmap_list, &m->mmap_list_elem);

  lock_acquire (&fs_lock);
  size = file_length (m->file);
  lock_release (&fs_lock);

  if (size == 0)
    return -1;

  while (size > 0)
    {
      size_t page_read_bytes = (size > PGSIZE) ? PGSIZE : size;
      size_t page_zero_bytes = PGSIZE - page_read_bytes;
      struct page *p;

      if ((p = page_make_entry (addr)) == NULL)
        goto munmap;
      m->pages++;

      p->type = PG_FILE;
      p->writable = true;

      p->file = f;
      p->read_bytes = page_read_bytes;
      p->zero_bytes = page_zero_bytes;
      p->file_ofs = ofs;

      size -= page_read_bytes;
      addr += PGSIZE;
      ofs  += page_read_bytes;
    }  

  return m->mapid;

 munmap:
  do_munmap (m, false);
  return -1;
}

System call munmap(mapid) unmaps the mapping designated by mapid, which must be a mapping id returned by a previous call to mmap by the same process that has not yet been unmapped.

void
sys_munmap (mapid_t mapid)
{
  struct thread *cur = thread_current ();
  struct page *p;
  struct mmap *m;
  size_t write_bytes;

  if ((m = find_mmap (mapid)) == NULL)
    return;

  do_munmap (m, true);
}

do_munmap(m, write_back) performs a core functionality of sys_munmap. It first closes the open file and removes mmap entry m from process's mapping list. Then, it writes back every user virtual page to the mmapped file only if write_back is true and this user page is dirty. Here, notice that the function pagedir_is_dirty returns false if a page is dirty or ``there is no mapping between virtual page and physical frame''. Finally, every SPTE and physical frame allocated for this SPTE, if any, are removed and freed. 

static void
do_munmap (struct mmap* m, bool write_back)
{
  void *upage;

  lock_acquire (&fs_lock);
  file_close (m->file);
  lock_release (&fs_lock);

  list_remove (&m->mmap_list_elem);

  for (upage = m->addr; upage < m->addr + PGSIZE * m->pages;
       upage += PGSIZE)
    {
      p = page_lookup (upage);
      if (write_back &&
          pagedir_is_dirty (cur->pagedir, upage))
        {
          lock_acquire (&fs_lock);
          write_bytes
            = file_write_at (p->file, p->upage, p->read_bytes, p->file_ofs);
          lock_release (&fs_lock);
        }
      page_remove_entry (p);
    }
  free (m);
}

All mappings are implicitly unmapped when a process exits, whether via exit or by any other means. When a mapping is unmapped, whether implicitly or explicitly, all pages written to by the process are written back to the file, and pages not written must not be. The pages are then removed from the process’s list of virtual pages.

void
sys_munmap_all (void)
{
  struct thread *cur = thread_current ();
  struct list *mmap_list = &cur->mmap_list;
  while (!list_empty (mmap_list))
    {
      struct mmap *m
        = list_entry (list_pop_front (mmap_list), struct mmap,
                      mmap_list_elem);
      do_munmap (m, true);
    }
}

void
process_exit (void)
{
  ...

  /* Unmap all mmap mappings. */
  sys_munmap_all ();

  ...
} 





## Notable dangerous points when removing FTE or SPTE

Function frame_free removes a given FTE and page_remove_entry removes a given SPTE with internally using frame_free only if a FTE is allocated for this SPTE. The frame_free is called only by two functions; one is page_remove_entry and the other is page_load. In page_load, frame_free is called only if loading the contents falis, and there is no problem.

When a process exits, all SPTEs owned by this process should be removed and freed. In addition, if some of the FTEs are allocated for these SPTEs, they should also be removed and freed. Here, we must consider eviction case. If a SPTE indicates that its contents are in a swap slot and file pointer is not NULL, then a user virtual page associated with this SPTE was first loaded from a file and then swapped out to a slot because it was dirty. In this case, if we 아무런 조치없이 SPTE를 free해버릴 경우, swap slots에서 leakage problem이 발생할 수 있으며, 해당 file에 변경 사항이 반영되지 않을 수 있다. Also, if a SPTE indicates that its contents are saved in a swap slot with null file pointer, 이때도 swap slots leakage problem을 고려해야한다.

Therefore, for any SPTE p, if p->slot != BITMAP_ERROR and p->file != NULL, then p->upage must be loaded from the swap slot (swap_in) and written back to the file (file_write_at) when p is removed. Meanwhile, if p->slot != BITMAP_ERROR and p->file == NULL, then the corresponding swap slot must freed. In this case, there is no need to call swap_in, that is, we just need to reset one bit in the used_map. For this purpose, we will define a function swap_free(slot).

void
swap_free (size_t slot)
{
  ASSERT (slot != BITMAP_ERROR);
  ASSERT (bitmap_all (used_map, slot, 1));
  bitmap_set_multiple (used_map, slot, 1, false);
}





## Synchronization



