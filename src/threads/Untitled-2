
# Analysis

## Page allocator (Palloc)

Virtual address space는 2개로 나뉨: user virtual address space (below PHYS_BASE), kernel virtual address space (above PHYS_BASE including PHYS_BASE).

Kernel virtual address space는 physical address space로 directyle mapped됨. e.g., PHYS_BASE + 0x1234는 0x1234로 매핑.
이 physical address space (RAM) 는 두개로 나뉨: kernel pool and user pool.

   System memory is divided into two "pools" called the kernel
   and user pools.  The user pool is for user virtual memory
   pages, the kernel pool for everything else.

핀토스에서 RAM size는 init_ram_pages (see threads/loader.h)에 기록됨. 대략 4MB로 정확히는 992 pages, that is 992 * 4KB = 3968KB임.

threads/init.c의 main function에서 palloc_init (user_page_limit)을 호출하는데 max (init_ram_pages / 2, user_page_limit) pages가 user pool로 주어지고 나머지는 kernel pool로 주어짐. Pintos에서는 RAM의 처음 1MB는 pool로 사용하지 않음. 따라서 init_ram_pages - 256 pages가 pool로 주어짐 (992 - 256 = 736 pages). 그리고 기본 pintos setting에서는 736 RAM pages를 반반 나눔. (368 pages)

void
palloc_init (size_t user_page_limit)
{
  /* Free memory starts at 1 MB and runs to the end of RAM. */
  uint8_t *free_start = ptov (1024 * 1024);
  uint8_t *free_end = ptov (init_ram_pages * PGSIZE);
  size_t free_pages = (free_end - free_start) / PGSIZE;
  size_t user_pages = free_pages / 2;
  size_t kernel_pages;
  if (user_pages > user_page_limit)
    user_pages = user_page_limit;
  kernel_pages = free_pages - user_pages;

  /* Give half of memory to kernel, half to user. */
  init_pool (&kernel_pool, free_start, kernel_pages, "kernel pool");
  init_pool (&user_pool, free_start + kernel_pages * PGSIZE,
             user_pages, "user pool");
}

/* By default, half of system RAM is given to the kernel pool and
   half to the user pool. */

각각의 pool은 bitmap (pool->used_map)을 이용해서 used/unused를 파악함. Pintos는 kernel pool을 관리하기 위한 bitmap은 kernel pool page에, user pool을 관리하기 위한 bitmap은 user pool page에 저장함. 대략 1 page씩 internal use를 위해 할당댐. 따라서 최종적으로, 기본 pintos setting에서 각 pool은 367 pages를 관리함.

/* Initializes pool P as starting at START and ending at END,
   naming it NAME for debugging purposes. */
static void
init_pool (struct pool *p, void *base, size_t page_cnt, const char *name) 
{
  /* We'll put the pool's used_map at its base.
     Calculate the space needed for the bitmap
     and subtract it from the pool's size. */
  size_t bm_pages = DIV_ROUND_UP (bitmap_buf_size (page_cnt), PGSIZE);
  if (bm_pages > page_cnt)
    PANIC ("Not enough memory in %s for bitmap.", name);
  page_cnt -= bm_pages;

  printf ("%zu pages available in %s.\n", page_cnt, name);

  /* Initialize the pool. */
  lock_init (&p->lock);
  p->used_map = bitmap_create_in_buf (page_cnt, base, bm_pages * PGSIZE);
  p->base = base + bm_pages * PGSIZE;
}

Palloc은 RAM의 free pages를 할당하여 이를 identifying하는 kernel virtual address (kpage)를 리턴함. PAL_USER flag가 있으면 user pool에서, 아니면 kernel pool에서 할당함. 각 pool에서 used_map의 ith bit가 false면 pool->base + PGSIZE * i에서 시작하는 page가 unused, true면 used (free page)임.

/* Obtains and returns a group of PAGE_CNT contiguous free pages.
   If PAL_USER is set, the pages are obtained from the user pool,
   otherwise from the kernel pool.  If PAL_ZERO is set in FLAGS,
   then the pages are filled with zeros.  If too few pages are
   available, returns a null pointer, unless PAL_ASSERT is set in
   FLAGS, in which case the kernel panics. */
void *
palloc_get_multiple (enum palloc_flags flags, size_t page_cnt)
{
  struct pool *pool = flags & PAL_USER ? &user_pool : &kernel_pool;
  void *pages;
  size_t page_idx;

  lock_acquire (&pool->lock);
  page_idx = bitmap_scan_and_flip (pool->used_map, 0, page_cnt, false);
  lock_release (&pool->lock);

  pages = pool->base + PGSIZE * page_idx;

  return pages;
}

위 코드에서 sanity check랑 initialization (PAL_ZERO)이랑 할당 fail 처리 (PAL_ASSERT)는 drop함.

## Page directory

Pintos에서 virtual address는 pd_no (22:31) + pt_no (12:21) + pg_ofs (0:11)로 구성댐.
pd_no를 이용해서 page directory (pd)를 access하는데, pd[pd_no] (pde)는 page table (pt)을 가리킴. (pyhs addr of page table + flags)
pt_no를 이용해서 page table (pt)을 access하는데, pt[pt_no] (pte)는 page를 가리킴. (pyhs addr of page bottom + flags)
그다음, pte에서 phys addr를 extract하고 pg_ofs를 더해서 실제 pyhs addr를 접근함.

threads/init.c의 main function에서 paging_init ()을 호출하는데, base page directory (init_page_dir)랑 page table을 setup함.
pde는 4 byte이고, pd_no는 10bit field이므로, page directory를 위해 4KB 공간 (1 page)이 필요함. pde 1K개, -> page table 1K개.
또, pte는 4 byte이고, pt_no는 10bit field이므로, page table을 위해 4KB 공간 (1 page)이 필요함. pte 1K개, -> page 1K개 (4MB populates).

애초에, init_ram_pages가 대략 1K 정도로 setup되기 때문에, 실제로는 pde가 1개 -> pt가 1개만 setup된다. (나머지는 filled with zeros)
즉, init_page_dir는 전체 RAM에 대한 mapping (one-to-one mapping from "kernel virtual address" space to RAM; user virtual mapping은 없음 아직.)을 가지고 있다. (mapping만 이루어지고, 할당은 안 된 상태임. 물론, page table을 위한 공간, page directory를 위한 공간만 할당됨.).
그리고, 초기화된 init_page_dir은 CPU의 CR3 register에 저장된다.

/* Populates the base page directory and page table with the
   kernel virtual mapping, and then sets up the CPU to use the
   new page directory.  Points init_page_dir to the page
   directory it creates. */
static void
paging_init (void)
{
  uint32_t *pd, *pt;
  size_t page;
  extern char _start, _end_kernel_text;

  pd = init_page_dir = palloc_get_page (PAL_ASSERT | PAL_ZERO);
  pt = NULL;
  for (page = 0; page < init_ram_pages; page++)
    {
      uintptr_t paddr = page * PGSIZE;
      char *vaddr = ptov (paddr);
      size_t pde_idx = pd_no (vaddr);
      size_t pte_idx = pt_no (vaddr);
      bool in_kernel_text = &_start <= vaddr && vaddr < &_end_kernel_text;

      if (pd[pde_idx] == 0)
        {
          pt = palloc_get_page (PAL_ASSERT | PAL_ZERO);
          pd[pde_idx] = pde_create (pt);
        }

      pt[pte_idx] = pte_create_kernel (vaddr, !in_kernel_text);   // PTE_U flag가 없음.
    }

  /* Store the physical address of the page directory into CR3
     aka PDBR (page directory base register).  This activates our
     new page tables immediately.  See [IA32-v2a] "MOV--Move
     to/from Control Registers" and [IA32-v3a] 3.7.5 "Base Address
     of the Page Directory". */
  asm volatile ("movl %0, %%cr3" : : "r" (vtop (init_page_dir)));
}

### Page directory for each process

각 process를 위한 page directory는 struct thread의 pagedir에 저장된다. 그리고 이 pagedir은 process가 load될 때 초기화된다 (pagedir_create).
pagedir_create은 paging_init에서 초기화한 init_page_dir을 shallow copy한다. 즉, page directory를 위한 공간 (1 page)만 각 process에 할당되고, page table들은 이들끼리 공유한다. 따라서, kernel virtual mapping은 모든 process가 공유한다.

/* Creates a new page directory that has mappings for kernel
   virtual addresses, but none for user virtual addresses.
   Returns the new page directory, or a null pointer if memory
   allocation fails. */
uint32_t *
pagedir_create (void) 
{
  uint32_t *pd = palloc_get_page (0);
  if (pd != NULL)
    memcpy (pd, init_page_dir, PGSIZE);
  return pd;
}

이렇게 만들어진 page directory는 pagedir_activate 함수를 호출하여 CR3 register에 store한다.

User process에서 user virtual page (below PHYS_BASE, upage)를 필요로할 때는, 이 page가 mapped될 공간을 palloc_get_page with PAL_USER flag를 통해 RAM의 user pool에서 할당한다 (kpage). 그러고 나서 pagedir_set_page (cur->pagedir, upage, kpage, writable)를 호출하여 page table (cur->pagedir[pd_no (upage)])에 mapping이 추가된다. 해당 page table이 없을 경우, 새롭게 할당하여 private pd에 추가한다. 따라서, 모든 process들은 kernel virtual mapping이 담긴 page table들은 공유하지만, user virtual mapping이 담긴 page table들은 private하다.

/* Adds a mapping in page directory PD from user virtual page
   UPAGE to the physical frame identified by kernel virtual
   address KPAGE.
   UPAGE must not already be mapped.
   KPAGE should probably be a page obtained from the user pool
   with palloc_get_page().
   If WRITABLE is true, the new page is read/write;
   otherwise it is read-only.
   Returns true if successful, false if memory allocation
   failed. */
bool
pagedir_set_page (uint32_t *pd, void *upage, void *kpage, bool writable)
{
  uint32_t *pte;
  ...
  pte = lookup_page (pd, upage, true);   // 해당 위치 pd[pd_no (upage)]에 table이 없으면 새롭게 할당한다. private.

  if (pte != NULL) 
    {
      ASSERT ((*pte & PTE_P) == 0);
      *pte = pte_create_user (kpage, writable);   // PTE_U flag가 추가됨.
      return true;
    }
  else
    return false;
}

예를 들어, 초기에, process P1이 upage 0x08048000를 필요로할 때는 P1->pagedir[pd_no (upage)]에 page table이 할당되어 연결되고, pyhsical frame 1이 할당되고 (identified by kpage1) 1로의 mapping이 이 pt에 추가된다.
Context switching이 일어나 process P2가 upage 0x08048000를 필요로할 때는 P2->pagedir[pd_no (upage)]에 page table이 할당되어 연결되고, pyhsical frame 2가 할당되고 (identified by kpage2) 2로의 mapping이 이 pt에 추가된다. 이때, 할당된 page table들은 P1과 P2 사이에서 공유가 일어나지 않으며, P1이 0x08048000을 위해 할당한 frame 1과 P2가 할당한 frame 2는 주소가 서로 다르며, kpage1과 kpage2 또한 그러하다.









/* Looks up the physical address that corresponds to user virtual
   address UADDR in PD.  Returns the kernel virtual address
   corresponding to that physical address, or a null pointer if
   UADDR is unmapped. */
void *
pagedir_get_page (uint32_t *pd, const void *uaddr) 
{
  uint32_t *pte;

  ASSERT (is_user_vaddr (uaddr));
  
  pte = lookup_page (pd, uaddr, false);
  if (pte != NULL && (*pte & PTE_P) != 0)
    return pte_get_page (*pte) + pg_ofs (uaddr);
  else
    return NULL;
}











Process가 execution을 끝낼 때는, process_exit에서 pagedir_destroy를 호출하여 user virtual address에 mapping된 모든 physical frame (palloced with PAL_USER flag)들이 할당해제된다. 이때, process들이 공유하는 kernel virtual mapping에 대해서는 할당 해제를 수행하지 않는다.

/* Destroys page directory PD, freeing all the pages it
   references. */
void
pagedir_destroy (uint32_t *pd) 
{
  uint32_t *pde;

  if (pd == NULL)
    return;

  ASSERT (pd != init_page_dir);
  for (pde = pd; pde < pd + pd_no (PHYS_BASE); pde++)
    if (*pde & PTE_P) 
      {
        uint32_t *pt = pde_get_pt (*pde);
        uint32_t *pte;
        
        for (pte = pt; pte < pt + PGSIZE / sizeof *pte; pte++)
          if (*pte & PTE_P) 
            palloc_free_page (pte_get_page (*pte));
        palloc_free_page (pt);
      }
  palloc_free_page (pd);
}

### Frame allocation failed

각각의 process가 upage를 load하기 위해 pyhsical frame을 palloc을 통해 할당하고 upage-frame mapping을 추가하다보면, user pool의 used_map이 모두 true, 즉 더 이상 할당 가능한 RAM page가 없을 수 있다. 이 경우, palloc은 NULL을 리턴하는데, frame eviction이 구현되어있지 않다.

User pool로부터 더 이상의 할당이 불가능할 경우, 다른 frame (자신의 frame 또는 다른 프로세스의 frame)을 evict하여 requesting process가 사용할 수 있도록 해야한다. Requirement.





## Current implementation

???





# Solutions to requirements

Lazy loading (supplemental page table), eviction (frame table), mmap system call, stack growth.

## Overview

1. Supplemental page table

A supplemental page table entry (SPTE)는 user virtual page에 대한 정보를 보충한다 (associated with user virtual page). Process마다 load를 요구하는 user virtual page들은 specific하므로 SPTE 또한 process-specific하다. SPTE는 해당 page가 file로부터 읽어들여 초기화를 해야하는지, 그냥 zeros로 채우는지, swap slots으로부터 읽어들이는지 등의 정보를 알려준다.

나중에 lazy loading을 구현하면, 아직 load되지 않은 user virtual page를 access하는 것은 page fault를 일으킨다. 이때, page fault handler에서 해당 page를 어떻게 load해야하는지에 대한 정보가 SPTE에 들어있다.

A supplemental page table (SPT)는 SPTE들을 보관하고 있는 structure이다. 각각의 SPTE는 process-specific하므로, SPT는 각각의 process마다 private하게 보관한다. 주어진 user virtual page에 대해 해당하는 SPTE를 빠르게 lookup하기 위해 hash table을 이용할 것이다.

2. Frame table

A frame table entry (FTE)는 a physical frame from user pool을 identifying하는 kernel virtual address를 hold한다. 즉, user virtual page를 load하기 위해 a physical frame을 할당할 경우 (palloced with PAL_USER), 해당하는 kernel virtual address를 hold하는 FTE가 만들어진다.

A frame table (FT)는 FTE들을 보관하고 있는 structure이다. RAM pages는 어느 process든지 할당할 수 있기 때문에, FT는 global하게 manage된다.

3. Swap slots

더 이상 RAM page를 할당할 수 없을 때, 이미 할당된 page를 evict할 필요가 있다. 이때, 이 page가 dirty하지 않을 경우는 상관이 없는데, dirty할 경우 contents를 backup해두어야 한다. 이때 사용되는 게 swap slots임. Swap slots은 disk에 존재하고 global하게 manage된다.




어떤 process P가 a user virtual page (upage)를 필요로할 때, P는 해당 page에 mapped될 physical frame을 바로 할당하지 않고, SPTE를 만들어서 SPT에 저장한다. 나중에, 이 process가 해당 page 영역을 access하면, not present page fault가 발생한다. 이때, page fault handler는 fault를 발생시킨 process (P)의 SPT에서 upage에 해당하는 SPTE를 찾는다. 그리고 upage를 위한 pyhsical frame을 할당하고 (using frame table manager, 이때 frame과 associated된 FTE가 만들어진다.), SPTE에 저장된 정보를 바탕으로, file이나 swap slot으로부터 contents를 읽어들이거나 zeros로 fill하여 frame을 초기화한다. 마지막으로, upage와 할당된 frame 사이에 mapping을 p->pagedir에 추가한다 (using pagedir_set_page).

Frame table manager can fail to allocate a frame for the user virtual page. 이때, eviction이 요구된다. The manager는 frame table에서 victim FTE을 찾고, 만약 frame이 dirty할 경우 swap slots에 backup하고나서 이 frame을 P에 넘겨준다.


그림.



## Data structures and operations

Supplemental page table entry (SPTE), supplemental page table (SPT), frame table entry (FTE), frame table (FT).

### Supplemental page table management

A supplemental page table entry (SPTE)는 user virtual page에 대한 정보를 보충한다 (associated with user virtual page). Process마다 load를 요구하는 user virtual page들은 specific하므로 SPTE 또한 process-specific하다. SPTE는 해당 page가 file로부터 읽어들여 초기화를 해야하는지, 그냥 zeros로 채우는지, swap slots으로부터 읽어들이는지 등의 정보를 알려준다. 만약, 이 user virtual page가 file로부터 load되어야 한다면, 해당 file에 대한 pointer, starting offset, read amounts에 대한 정보가 추가적으로 필요하다. In the case of loading from a swap slot, which swap slot에 대한 정보, 즉 index가 필요하다. 또한, SPTE->upage를 loading하면서 a physical frame이 할당될 경우, 이 SPTE에는 할당된 frame과 associated된 FTE에 대한 pointer가 저장된다.

/* How to load a user virtual pages? */
enum page_type
  {
    PG_FILE = 1,            /* Load from file. */
    PG_SWAP = 2,            /* Load from swap slot. */
    PG_ZERO = 3,            /* Zero page contents. */
    PG_UNKNOWN = 4          /* Unknown (for debugging purposes). */
  };

/* Supplemental page table entry (SPTE). */
struct page
  {
    void *upage;            /* User virtual page. */
    struct frame *frame;    /* A FTE which is allocated for this SPTE. */

    struct thread *owner;   /* An owner thread. */

    enum page_type type;    /* How to load this page? */
    bool writable;          /* Is page writable? */

    /* Meaningful if type is PG_FILE. */
    struct file *file;      /* A file this page will be loaded from. */
    off_t file_ofs;         /* Offset. */
    size_t read_bytes;      /* File read amount. */
    size_t zero_bytes;      /* PGSIZE - read_bytes. */

    /* Meaningful if type is PG_SWAP. */
    size_t slot;            /* A swap slot index this page will be loaded from. */

    struct hash_elem hash_elem;
  };

SPT의 life cycle은 아래 두 함수를 통해 관리된다.

struct hash *page_create_spt (void);
void page_destroy_spt (struct hash *spt);





page_create_spt는 SPTE를 보관하기 위한 SPT를 만들고 초기화한다 (managed as hash table). 이 hash table은 SPTE의 upage를 key로 entries를 저장한다 (see page_hash_func and page_hash_less).

struct hash *
page_create_spt (void)
{
  struct hash *spt = malloc (sizeof (struct hash));
  if (!spt)
    PANIC ("cannot create supplemental page table.");
  hash_init (spt, page_hash_func, page_hash_less, NULL);
  return spt;
}

Process가 program을 load할 때 SPT를 만든다.

bool
load (const char *exec_path, void (**eip) (void), void **esp) 
{
  ...

  t->spt = page_create_spt ();
  if (t->spt == NULL)
    goto done;

  ...
}

이렇게 만들어진 SPT는 process가 exit할 때 resource를 deallocate해야 한다.

void
process_exit (void)
{
  struct thread *cur = thread_current ();
  struct hash *spt;

  ...
  
  spt = cur->spt;
  if (spt != NULL)
    page_destroy_spt (spt);
  
  ...
}

page_destroy_spt는 주어진 SPT에 저장된 모든 SPTE에 대해 할당을 해제한다. ***** SPTE를 할당 해제할 때는 synchronization을 고려해야한다. *****

void
page_destroy_spt (struct hash *spt)
{
  ASSERT (spt != NULL);
  hash_destroy (spt, page_hash_free);
  free (spt);
}

static void
page_hash_free (struct hash_elem *e, void *aux UNUSED)
{
  struct page *p = hash_entry (e, struct page, hash_elem);
  struct frame *f = p->frame;
  ...// Synchronization
  free (p);
}




각 process는 page_make_entry 함수를 이용하여 SPTE를 생성하고 이 process의 SPT에 저장한다. 이 함수는 생성된 SPTE를 가리키는 pointer를 리턴하는데, 이를 이용하여 type을 설정하고 필요한 정보들(e.g., file, offset, read_bytes)을 설정해야한다.

struct page *
page_make_entry (void *upage)
{
  struct thread *cur = thread_current ();
  struct page *p;

  if (page_lookup (upage))
    return NULL;
  if ((p = malloc (sizeof (struct page))) == NULL)
    PANIC ("cannot create supplemental page table entry.");
  
  p->upage = upage;
  p->frame = NULL;
  p->owner = cur;

  p->type = PG_UNKNOWN;
  p->file = NULL;
  p->slot = BITMAP_ERROR;

  hash_insert (cur->spt, &p->hash_elem);
  return p;
}

Here, finding a SPTE associated with given upage is performed by page_lookup. This function returns a pointer to the corresponding SPTE if exists, or NULL otherwise. Therefore, in the function page_make_entry, a request to create an already existing SPTE is denied.

struct page *
page_lookup (void *upage)
{
  struct thread *cur = thread_current ();
  struct page key;
  struct hash_elem *e;

  key.upage = upage;
  e = hash_find (cur->spt, &key.hash_elem);

  return e != NULL ? hash_entry (e, struct page, hash_elem) : NULL;
}

User virtual page upage에 대해 page를 loading할 때는 page_load 함수를 이용한다. ***** lazy loading에서 설명 *****

bool page_load (void *);
struct page *page_lookup (void *);





### Frame table management

User process에서 만든 SPTEs를 이용하여 user virtual pages를 loading할 때, pyhsical frame을 할당해주어야 한다. 원래는 palloc_get_page (PAL_USER)를 이용하여 physical frame을 user pool에서 할당한 후 이를 identifying하는 kernel virtual address를 리턴하는데, 이제는 we will use operations on FTEs (not directly using palloc).

A frame table entry (FTE)는 a physical frame allocated from user pool을 identifying하는 kernel virtual address를 hold한다. 만약, SPTE->upage를 위해 a physical frame F가 allocated되었다면, F와 associated된 FTE에는 이 SPTE가 기록된다.

/* Frame table entry (FTE). */
struct frame
  {
    void *kpage;            /* Kernel virtual page identifying a physical frame. */
    struct page *suppl;     /* A SPTE which requested this FTE. */

    struct thread *owner;   /* An owner thread (for debugging purposes). */

    struct list_elem list_elem;
  };

A frame table (FT)는 FTE들을 보관하고 있는 structure이다. 이 table은 global하고 모든 processes들이 접근할 수 있기때문에, searching, inserting, removing an FTE는 synchronized되어야한다.

static struct lock table_lock;   /* Mutual exclusion. */
static struct list frame_list;   /* Mapped frames (list). */

FT는 kernel이 실행될 때 threads/init.c의 main function에서 한 번 초기화된다.

void
frame_init (void)
{
  lock_init (&table_lock);
  list_init (&frame_list);
}

int
main (void)
{
  ...
  frame_init ();
  ...
}



Phsical frame을 할당하여 이를 identifying하는 kernel virtual page를 리턴하거나 할당을 해제하는 것은 palloc을 통해 직접 이루어지지 않고, FTE에 wrapped되어 frame_alloc과 frame_free함수를 통해 간접적으로 이루어진다.

struct frame *frame_alloc (struct page *p);
void frame_free (struct frame *f);

frame_alloc(p)는 SPTE p를 위해 RAM page를 할당하는 기능을 수행한다. A physical frame이 SPTE p를 위해 할당될 때, FTE가 하나 만들어지고 이 frame을 identifying하는 kernel virtual address가 FTE에 저장된다. 또한, 할당을 요청한 SPTE p를 가리키는 pointer도 setup된다. 이렇게 만들어진 FTE는 FT에 저장이 되는데, 이 전 과정은 lock을 이용하여 atomic하게 이루져야한다.

struct frame *
frame_alloc (struct page *p)
{
  struct thread *cur = thread_current ();
  struct frame *f;

  lock_acquire (&table_lock);

  if ((f = malloc (sizeof (struct frame))) == NULL)
    PANIC ("cannot allocate frame table entry.");

  f->kpage = palloc_get_page (PAL_USER));
  if (f->kpage != NULL)
    {
      f->owner = p->owner;
      f->suppl = p;

      list_push_back (&frame_list, &f->list_elem);
      lock_release (&table_lock);

      return f;
    }
  else
    PANIC ("eviction required. covered later.");
}




*****

void
frame_free (struct frame *f)
{
  ...
}





더 이상 할당 가능한 physical frame이 없을 때에는 victim frame을 찾아야 하는데, 이는 frame_get_victim 함수를 통해 이루어진다. ***** eviction에서 설명 *****

struct frame *frame_get_victim (void);





### Swap slots management

더 이상 RAM page를 할당할 수 없을 때, 이미 할당된 physical frame을 evict할 필요가 있다. 이때, 이 page가 dirty하지 않을 경우는 상관이 없는데, dirty할 경우 contents를 backup해두어야 한다. 이때 사용되는 게 swap slots이다. Swap slots은 global한 disk 영역에 존재하기 때문에, frame table과 마찬가지로 accessing swap slots은 synchronized되어야한다.

static struct lock swap_lock;

각 swap slot은 page size만큼의 연속된 disk sectors를 populate한다. Size of a disk sector는 BLOCK_SECTOR_SIZE에 define되어 있다. 따라서, page-size swap slot을 위해 필요한 sector의 개수는 PGSIZE / BLOCK_SECTOR_SIZE가 된다.

#define PAGE_SECTOR_CNT (PGSIZE / BLOCK_SECTOR_SIZE)

여러 swap slots들 중에서 사용 중인 slots과 free slots을 구분해야 하는데, 이를 위해서 palloc.c의 implementation과 같이 bitmap used_map을 이용한다. used_map의 ith bit가 true이면 ith slot이 사용 중이고, 그렇지 않으면 free slot이다.

static struct bitmap *used_map;



Swap slots manger는 kernel이 실행될 때 threads/init.c의 main function에서 한 번 초기화된다. Document에서 제시한 대로, we will use the BLOCK_SWAP block device for swapping, obtaining the struct block that represents it by calling block_get_role().

static struct block *swap_bdev;
static size_t swap_slots;

void
swap_init (void)
{
  if (!(swap_bdev = block_get_role (BLOCK_SWAP)))
    PANIC ("possible?");

  swap_slots = block_size (swap_bdev) / PAGE_SECTOR_CNT;
  used_map = bitmap_create (swap_slots);

  if (!used_map)
    PANIC ("bitmap allocation failed.");
  
  lock_init (&swap_lock);
}

int
main (void)
{
  ...
  swap_init ();
  ...
}

Physical frame의 contents를 swap slot에 write하고 read하는 작업은 swap_out과 swap_in을 통해 각각 이루어진다.

size_t swap_out (void *kpage);
void swap_in (void *kpage, size_t slot);

swap_out 함수는 swap_bdev에서 free slot을 찾아서 해당하는 slot에 pyhsical frame의 contents를 write한다.

size_t
swap_out (void* kpage)
{
  size_t size = PGSIZE;
  size_t slot;
  block_sector_t sector;
  int i;

  lock_acquire (&swap_lock);
  slot = bitmap_scan_and_flip (used_map, 0, 1, false);
  lock_release (&swap_lock);

  if (slot != BITMAP_ERROR)
    {
      sector = slot * PAGE_SECTOR_CNT;
      for (i = 0; i < PAGE_SECTOR_CNT; i++)
        {
          block_write (swap_bdev, sector + i,
                       kpage + BLOCK_SECTOR_SIZE * i);
        }
      return slot;
    }
  else
    PANIC ("cannot find any free swap slot.");
}

이렇게 backup된 contents는 나중에 swap_in 함수를 이용하여 user virtual page에 mapped된 pyhsical frame에 restore될 수 있다.

void
swap_in (void *kpage, size_t slot)
{
  block_sector_t sector;
  int i;

  sector = slot * PAGE_SECTOR_CNT;
  for (i = 0; i < PAGE_SECTOR_CNT; i++)
    {
      block_read (swap_bdev, sector + i,
                  kpage + BLOCK_SECTOR_SIZE * i);
    }

  bitmap_set_multiple (used_map, slot, 1, false);
}

## Lazy loading

Currently, executable code and data segments are directly loaded in memory during process setup. However, we have to modify some portion of the current implementation so that only a stack setup part is directly loaded when a process starts. That is, when a process is loading a program, every necessary page (except stack) is not loaded during the time. 따라서, 나중에 procee가 unloaded segments에 접근하면 not-present page fault가 발생하는데, 이때 page fault handler가 해당 user virtual pages을 load하고 process의 execution을 resume하도록 해야한다.

Page fault handler가 해당 user virtual page를 어떻게 load해야 하는지 알기 위해서는 process가 SPTE들을 만들어서 필요한 정보들을 저장해 두어야 한다. Therefore, we will modify load_segment in userprog/process.c so that it just makes SPTE which contains supplemental information without allocating any physical frame.

static bool
load_segment (struct file *file, off_t ofs, uint8_t *upage,
              uint32_t read_bytes, uint32_t zero_bytes, bool writable) 
{
  ...
  while (read_bytes > 0 || zero_bytes > 0) 
    {
      size_t page_read_bytes = read_bytes < PGSIZE ? read_bytes : PGSIZE;
      size_t page_zero_bytes = PGSIZE - page_read_bytes;
      struct page *p;

      if ((p = page_make_entry (upage)) == NULL)
        return false;
      if (page_read_bytes > 0)
        {
          p->type = PG_FILE;
          p->file = file;
          p->file_ofs = ofs;
        }
      else
        p->type = PG_ZERO;
      
      p->writable = writable;
      p->read_bytes = page_read_bytes;
      p->zero_bytes = page_zero_bytes;

      read_bytes -= page_read_bytes;
      zero_bytes -= page_zero_bytes;
      upage += PGSIZE;
      ofs += page_read_bytes;
    }
  return true;
}

Process가 these not present pages에 access할 때, page fault가 발생하고 fault address가 contain된 user virtual page를 얻어 page_load 함수를 호출한다.

static void
page_fault (struct intr_frame *f) 
{
  ...
  asm ("movl %%cr2, %0" : "=r" (fault_addr));
  fault_page = pg_round_down (fault_addr);

  ...
  if (not_present)
    {
      if (!page_load (fault_page))
        sys_exit (-1);
      return;
    }

  if (!user)
    {
      f->eip = (void (*) (void)) f->eax;
      f->eax = (uint32_t) SYS_BAD_ADDR;
      return;
    }

  kill (f);
}


page_load looks up the SPTE that is associated with virtual page that faulted in the process's SPT. 그리고 SPTE p에 FTE와 physical frame을 할당한다 using frame_alloc (p). 이후, p->type에 따라 file이나 swap slot에서 contents를 read하거나 zeros로 fill한다. 마지막으로 install_page 함수를 이용하여 이 process에 user virtual mapping을 추가한다.

bool
page_load (void *upage)
{
  bool success = false;
  struct page *p = page_lookup (upage);
  struct frame *f;

  if (!p)
    return false;

  f = p->frame = frame_alloc (PAL_USER, p);
  if (p->file != NULL)
    {
      size_t read_bytes
        = file_read_at (p->file, f->kpage, p->read_bytes, p->file_ofs);
      if (read_bytes != p->read_bytes)
        {
          frame_free (f);
          return false; 
        }
      memset (f->kpage + p->read_bytes, 0, p->zero_bytes);
    }
  else if (p->slot != BITMAP_ERROR)
    PANIC ("p should have been once evicted. covered later.");
  else
    memset (f->kpage, 0, PGSIZE);

  if (!install_page (upage, f->kpage, p->writable)) 
    {
      frame_free (f);
      return false; 
    }

  frame_unlock (f);

  return true;
}

The function install_page(upage, kpage, writable) adds a mapping from user virtual page to kernel virtual page that is identifying a physical frame to the calling process's pagedir. If writable is true, the user process may modify the page, otherwise, it is read-only. In this function upage must not already be mapped. It returns true on success, false if upage is already mapped or if memory allocation fails.

static bool
install_page (void *upage, void *kpage, bool writable)
{
  struct thread *t = thread_current ();
  return (pagedir_get_page (t->pagedir, upage) == NULL
          && pagedir_set_page (t->pagedir, upage, kpage, writable));
}





## Stack growth

// stack은 lazy load x

The current implementation imposes a fixed size on the stack (single page). That is, a stack cannot grow down below the limited size. The requirement is to make it available to increase a size of the stack. We will impose a maximum limit on stack growth (STACK_MAX, 8MB). Lazy loading과 비슷하게, ESP register가 fixed-size stack 밑을 access할 경우 page fault가 발생한다. 이때, the handler first check whether a it needs a stack growth or not. If stack growth is needed, the handler retrieves a required stack page address. After this, it makes a SPTE associated with this stack page, and then 바로 page_load를 호출한다.

To check whether the stack growth is necessary, we use this condition.

static bool
stack_growth (void *vaddr, void *esp)
{
  return vaddr > (PHYS_BASE - STACK_MAX)
         && vaddr <= (PHYS_BASE - 1);
         && vaddr >= (esp - 32);
}

Using this function, page fault handler checks the necessity of stack growth, makes SPTE, and then loads it.

static void
page_fault (struct intr_frame *f) 
{
  ...
  asm ("movl %%cr2, %0" : "=r" (fault_addr));
  fault_page = pg_round_down (fault_addr);

  esp = user ? f->esp : cur->saved_esp;
  if (stack_growth (fault_addr))
    {
      if ((p = page_make_entry (fault_page)))
        {
          p->type = PG_ZERO;
          p->writable = true;
        }
    }

  if (not_present)
    {
      if (!page_load (fault_page))
        sys_exit (-1);
      return;
    }

  ...
  kill (f);
}

Here, we need to obtain the current value of the user program's stack pointer. If a page fault occurs in the user program, we can retrieve it from the esp member of the intr_frame f. On the other hand, we cannot retrieve it from f if a page fault occured in the kernel, because the processor only saves the stack pointer when an exception causes a ``switch" from user to kernel mode. Thus, in this case, reading esp out of the struct intr_frame passed to page_fault() would yield an undefined value. So we've saved esp into struct thread on the initial transition from user to kernel mode.

static void
syscall_handler (struct intr_frame *f) 
{
  struct thread *cur = thread_current ();
  cur->saved_esp = esp;
  ...
}





## Evicting a frame



## File memory mapping

Two system calls should be implemented; mmap and munmap. Therfore SYSCALL_CNT is increased from 13 to 15, and two system call wrappers and two core system call functionalities will be added.

#define SYSCALL_CNT 15

static void sys_mmap_wrapper   (struct intr_frame *);
static void sys_munmap_wrapper (struct intr_frame *);

mapid_t sys_mmap (int, void *);
void    sys_munmap (mapid_t);

In each process context, there can be several mmap mappings. Therefore, each process needs to keep these mappings. In addition, each mapping should contain its id and information about which file is mapped and which virtual page this mapping starts from.

/* A mmap mapping. */
struct mmap
  {
    struct list_elem mmap_list_elem;   /* List element. */
    struct file *file;                 /* File. */
    mapid_t mapid;                     /* Mmap id. */
    
    /* A user virtual page from which mapping starts. */
    void *addr;
    size_t pages;
  };

struct thread
  {
    ...

    /* Shared between thread.c and syscall.c. */
    struct list mmap_list;   /* List of mmap mappings. */
    int next_mapid;          /* Next file descriptor number. */

    ...
  };

Here, mmap_list and next_mapid are initialized by init_thread(), and the initial value of next_mapid is 0.

System call mmap(fd, addr) maps the file open as fd into the process's virtual address space. The entire file is mapped into consecutive virtual pages starting at addr. If the file's length is not a multiple of PGSIZE, then some bytes in the final mapped page "stick out" beyond the end of the file. *****Set these bytes to zero when the page is faulted in from the file system, and discard them when the page is written back to disk.***** This function returns, if successful, a mapping id thaa uniquely indentifies the mapping within the process. On failure, it returns -1 and the process's mappings are unchanged.

A call to mmap may fail if the file open as fd has a length of zero bytes. It must fail if addr is not ``page-aligned'' or if the range of pages mapped overlaps any existing set of mapped pages, including the stack or pages mapped at executable load time. It must also fail if addr is 0, because some Pintos code assumes virtual page 0 is not mapped. Finally, file descriptors 0 and 1, representing console input and output, are not mappable.

Closing or removing a file does not unmap any of its mappings. Once created, a mapping is valid until munmap is called or the process exits, following the Unix convention. We should use the file_reopen function to obtain a separate and independent reference to the file for each of its mappings.

/*Your VM system must lazily load pages in mmap regions and use the mmaped file itself as backing store for the mapping. That is, evicting a page mapped by mmap writes it back to the file it was mapped from.*/

mapid_t
sys_mmap (int fd_no, void *addr)
{
  struct thread *cur = thread_current ();
  struct file_desc *fd;
  struct file *f;
  struct mmap *m;
  size_t size;
  off_t ofs = 0;

  if (fd_no == STDIN_FILENO || fd_no == STDOUT_FILENO)
    return -1;
  if (addr == NULL || pg_ofs (addr) != 0)
    return -1;
  if ((fd = find_file_desc (fd_no)) == NULL)
    return -1;
  if ((m = malloc (sizeof (struct mmap))) == NULL)
    return -1;
  
  lock_acquire (&fs_lock);
  if ((f = file_reopen (fd->file)) == NULL)
    {
      lock_release (&fs_lock);
      free (m);
      return -1;
    }
  lock_release (&fs_lock);

  m->file = f;
  m->mapid = cur->next_mapid++;
  m->addr = addr;
  m->pages = 0;
  list_push_back (&cur->mmap_list, &m->mmap_list_elem);

  lock_acquire (&fs_lock);
  size = file_length (m->file);
  lock_release (&fs_lock);

  if (size == 0)
    return -1;

  while (size > 0)
    {
      size_t page_read_bytes = (size > PGSIZE) ? PGSIZE : size;
      size_t page_zero_bytes = PGSIZE - page_read_bytes;
      struct page *p;

      if ((p = page_make_entry (addr)) == NULL)
        goto munmap;
      m->pages++;

      p->type = PG_FILE;
      p->writable = true;

      p->file = f;
      p->read_bytes = page_read_bytes;
      p->zero_bytes = page_zero_bytes;
      p->file_ofs = ofs;

      size -= page_read_bytes;
      addr += PGSIZE;
      ofs  += page_read_bytes;
    }  

  return m->mapid;

 munmap:
  do_munmap (m, false);
  return -1;
}

System call munmap(mapid) unmaps the mapping designated by mapid, which must be a mapping id returned by a previous call to mmap by the same process that has not yet been unmapped.

void
sys_munmap (mapid_t mapid)
{
  struct thread *cur = thread_current ();
  struct page *p;
  struct mmap *m;
  size_t write_bytes;

  if ((m = find_mmap (mapid)) == NULL)
    return;

  do_munmap (m, true);
}

do_munmap(m, write_back) performs a core functionality of sys_munmap. It first closes the open file and removes mmap entry m from process's mapping list. Then, it writes back every user virtual page to the mmapped file only if write_back is true and this user page is dirty. Here, notice that the function pagedir_is_dirty returns false if a page is dirty or ``there is no mapping between virtual page and physical frame''. Finally, every SPTE and physical frame allocated for this SPTE, if any, are removed and freed. 

static void
do_munmap (struct mmap* m, bool write_back)
{
  void *upage;

  lock_acquire (&fs_lock);
  file_close (m->file);
  lock_release (&fs_lock);

  list_remove (&m->mmap_list_elem);

  for (upage = m->addr; upage < m->addr + PGSIZE * m->pages;
       upage += PGSIZE)
    {
      p = page_lookup (upage);
      if (write_back &&
          pagedir_is_dirty (cur->pagedir, upage))
        {
          lock_acquire (&fs_lock);
          write_bytes
            = file_write_at (p->file, p->upage, p->read_bytes, p->file_ofs);
          lock_release (&fs_lock);
        }
      page_remove_entry (upage);
    }
  free (m);
}

All mappings are implicitly unmapped when a process exits, whether via exit or by any other means. When a mapping is unmapped, whether implicitly or explicitly, all pages written to by the process are written back to the file, and pages not written must not be. The pages are then removed from the process’s list of virtual pages.

void
sys_munmap_all (void)
{
  struct thread *cur = thread_current ();
  struct list *mmap_list = &cur->mmap_list;
  while (!list_empty (mmap_list))
    {
      struct mmap *m
        = list_entry (list_pop_front (mmap_list), struct mmap,
                      mmap_list_elem);
      do_munmap (m, true);
    }
}

void
process_exit (void)
{
  ...

  /* Unmap all mmap mappings. */
  sys_munmap_all ();

  ...
}





## Synchronization



